# Module PRs - Master Index

**Project**: MCP Tool Code Interpreter Generator  
**Main PR**: ProjectRequirements.instructions.md  
**Status**: Module breakdown complete

---

## Overview

This directory contains detailed Project Requirements for each module of the MCP Tool Code Generator. Each module PR is self-contained with:
- Purpose and scope
- Implementation details
- Data structures
- Testing requirements
- Dependencies
- Examples

---

## Module Dependency Graph

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     01_data_models                          â”‚
â”‚  (ToolSpec, ToolCandidate, ValidationReport, CodeMetrics)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚02_llm_client â”‚ â”‚  utils (TBD) â”‚ â”‚ metrics (TBD)    â”‚
â”‚  (Qwen/vLLM) â”‚ â”‚              â”‚ â”‚ code_bleu, etc.  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  03_intent_extraction                   â”‚
â”‚  (Parse query, gap detection)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  04_spec_generator (TBD)                     â”‚
â”‚  (Generate ToolSpec from intent)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  05_code_generator (TBD)                     â”‚
â”‚  (Generate Python code from spec)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  06_validator (TBD)                          â”‚
â”‚  (Schema, sandbox, tests, metrics)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  07_executor (TBD)                           â”‚
â”‚  (Run staged tool, capture artifacts)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  08_presenter (TBD)                          â”‚
â”‚  (Format output, request approval)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  09_feedback_handler (TBD)                   â”‚
â”‚  (Parse user response, decide approval)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
        â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚10_promoter   â”‚ â”‚11_repair     â”‚
â”‚(Register)    â”‚ â”‚(Fix & retry) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Completed Module PRs

### âœ… 01 - Data Models (`01_data_models_PR.md`)
**Priority**: P0 (Foundation)  
**Status**: Complete  
**Effort**: 2-3 days

**Key Components**:
- `ToolStatus`, `ToolSpec`, `ToolCandidate`
- `CodeMetrics`, `FunctionalCorrectnessMetrics`, `SemanticClosenessMetrics`
- `ValidationReport`, `RunArtifacts`, `UserFeedback`
- `RegistryMetadata`

**Tests**: >95% coverage required

---

### âœ… 02 - LLM Client (`02_llm_client_PR.md`)
**Priority**: P0 (Core service)  
**Status**: Complete  
**Effort**: 2-3 days

**Key Components**:
- `BaseLLMClient` (abstract interface)
- `QwenLLMClient` (on-prem via vLLM)
- `AnthropicClient`, `OpenAIClient` (optional cloud)
- Prompt template management
- Structured JSON generation

**Configuration**: Qwen2.5-Coder-32B (4-bit) for 48GB VRAM

---

### âœ… 03 - Intent Extraction (`03_intent_extraction_PR.md`)
**Priority**: P0 (Entry point)  
**Status**: Complete  
**Effort**: 2-3 days

**Key Components**:
- `UserIntent` model
- `IntentExtractor` (pattern + LLM)
- `GapDetector` (overlap scoring)
- `analyze_user_request()` main function

**Gap Detection**: 5-component weighted scoring (â‰¥85% threshold)

---

### âœ… 04 - Spec Generator (`04_spec_generator_PR.md`)
**Priority**: P0 (Core)  
**Status**: Complete  
**Effort**: 2-3 days

**Key Components**:
- Generate ToolSpec from UserIntent
- JSON Schema generation (input/output)
- Reference tool matching
- LLM-based spec generation

---

### âœ… 05 - Code Generator (`05_code_generator_PR.md`)
**Priority**: P0 (Core)  
**Status**: Complete  
**Effort**: 3-4 days

**Key Components**:
- Generate Python code from ToolSpec
- Template-based + LLM-based generation
- MCP decorator and metadata
- Test generation
- Code formatting (black/isort)

---

### âœ… 06 - Validator (`06_validator_PR.md`)
**Priority**: P0 (Quality gate)  
**Status**: Complete  
**Effort**: 4-5 days

**Key Components**:
- Syntax validation (AST)
- Static analysis (mypy, pylint)
- Schema compliance
- Sandbox execution
- Code metrics (optional)
- Repair suggestions

---

### âœ… 07 - Executor (`07_executor_PR.md`) - THE CODE INTERPRETER CORE
**Priority**: P1 (Execution engine)  
**Status**: Complete  
**Effort**: 2-3 days

**Key Components**:
- **Load and execute generated Python code**
- Isolated environment execution
- Timeout handling
- Resource measurement
- Artifact capture

**Note**: This is the actual "interpreter" that runs generated code

---

### âœ… 08 - Presenter (`08_presenter_PR.md`)
**Priority**: P1 (UI)  
**Status**: Complete  
**Effort**: 1-2 days

**Key Components**:
- Format execution results (markdown)
- Generate approval prompts (2-stage)
- DataFrame preview

---

### âœ… 09 - Feedback Handler (`09_feedback_handler_PR.md`)
**Priority**: P0 (Decision point)  
**Status**: Complete  
**Effort**: 1-2 days

**Key Components**:
- Parse user responses (strict token matching)
- Two-stage approval logic
- Ambiguous response handling

---

### âœ… 10 - Promoter (`10_promoter_PR.md`)
**Priority**: P0 (Registry)  
**Status**: Complete  
**Effort**: 2 days

**Key Components**:
- Promote tools from staging to active
- Version conflict handling
- Registry metadata updates

---

### âœ… 11 - Utils Package (`11_utils_package_PR.md`)
**Priority**: P0 (Foundation)  
**Status**: Complete  
**Effort**: 2-3 days

**Key Components**:
- CSV helpers (load, type detection)
- Type detection (numeric, categorical, datetime)
- Validation helpers
- Security helpers (import allowlist, path validation)

---

### âœ… 12 - Metrics Package (`12_metrics_package_PR.md`)
**Priority**: P2 (Optional for MVP)  
**Status**: Complete  
**Effort**: 5-7 days

**Key Components**:
- Functional correctness
- Pass@k calculation
- Code BLEU (n-gram, AST, dataflow)
- Test pass rate

**Note**: Optional for MVP, recommended for production

---

### âœ… 13 - Pipeline Orchestrator (`13_pipeline_orchestrator_PR.md`) - **THE CODE INTERPRETER**
**Priority**: P0 (CRITICAL - Main Entry Point)  
**Status**: Complete  
**Effort**: 3-4 days

**Key Components**:
- **Main `CodeInterpreterPipeline` class - This IS the "Code Interpreter"**
- Orchestrates all modules (Intent â†’ Spec â†’ Code â†’ Validate â†’ Execute â†’ Approve)
- Gap detection (reuse existing tools)
- Validation with repair loop (max 3 attempts)
- Two-stage approval workflow
- CLI interface (`src/cli.py`)
- MCP server integration (`src/mcp_server.py`)
- Complete state machine
- Error recovery

**Note**: **This is the main interface users interact with to interpret queries and execute generated code**

---

## Remaining Module PRs (To Be Created)

### ðŸ”² 04 - Spec Generator
**Priority**: P0  
**Estimated Effort**: 2 days

**Scope**:
- Generate ToolSpec from UserIntent
- Create JSON schemas (input/output)
- Generate documentation sections
- Validate spec completeness

**Depends on**: 01, 02, 03

---

### ðŸ”² 05 - Code Generator
**Priority**: P0  
**Estimated Effort**: 3 days

**Scope**:
- Generate Python code from ToolSpec
- Apply code templates
- Add error handling
- Generate tests
- Format with black/isort

**Depends on**: 01, 02, 04

---

### ðŸ”² 06 - Validator
**Priority**: P0  
**Estimated Effort**: 4-5 days

**Scope**:
- Schema validation
- Static analysis (mypy, pylint)
- Sandbox execution
- Test case generation and execution
- Code metrics calculation (functional correctness, pass@k, code BLEU)
- Repair loop coordinator

**Depends on**: 01, 02, 05, Metrics modules

---

### ðŸ”² 07 - Executor
**Priority**: P1  
**Estimated Effort**: 2 days

**Scope**:
- Load staged tool in isolation
- Execute with user data
- Capture outputs and artifacts
- Measure execution time
- Handle errors gracefully

**Depends on**: 01, 05

---

### ðŸ”² 08 - Presenter
**Priority**: P1  
**Estimated Effort**: 1-2 days

**Scope**:
- Format tool output (markdown)
- Generate tool summary
- Create approval prompt (2-stage)
- Handle output display

**Depends on**: 01, 07

---

### ðŸ”² 09 - Feedback Handler
**Priority**: P0  
**Estimated Effort**: 1-2 days

**Scope**:
- Parse user responses
- Strict token matching (Approve/Reject)
- Two-stage approval flow
- Extract rejection reasons

**Depends on**: 01

---

### ðŸ”² 10 - Promoter
**Priority**: P0  
**Estimated Effort**: 2 days

**Scope**:
- Copy tool from staging to active
- Update registry metadata
- Version management
- Idempotency checks
- Reload MCP server

**Depends on**: 01

---

### ðŸ”² 11 - Repair Coordinator
**Priority**: P1  
**Estimated Effort**: 2 days

**Scope**:
- Parse validation errors
- Generate repair prompts
- Track repair iterations (max 3)
- Improvement delta tracking

**Depends on**: 02, 06

---

### ðŸ”² 12 - Metrics Package
**Priority**: P2 (Optional for MVP)  
**Estimated Effort**: 5-7 days

**Submodules**:
- `functional_correctness.py` - Reference solution comparison, test execution
- `pass_at_k.py` - Pass@k calculation
- `test_pass_rate.py` - Test suite management
- `code_bleu.py` - Combined Code BLEU
- `ngram_matcher.py` - N-gram and weighted n-gram
- `ast_matcher.py` - AST-based similarity
- `dataflow_analyzer.py` - Variable flow analysis

**Depends on**: 01

---

### ðŸ”² 13 - Pipeline Orchestrator (THE CODE INTERPRETER)
**Priority**: P0 (CRITICAL - Main Entry Point)  
**Estimated Effort**: 3-4 days

**Scope**:
- **This IS the "Code Interpreter"** - main interface users interact with
- Orchestrates all modules: Intent â†’ Spec â†’ Code â†’ Validate â†’ Execute â†’ Approve
- Implements state machine (DRAFT â†’ STAGED â†’ APPROVED â†’ PROMOTED)
- Gap detection (reuse existing tools when possible)
- Validation with automatic repair loop (max 3 attempts)
- Two-stage approval workflow
- CLI interface and MCP server integration
- Error recovery and logging

**Depends on**: All modules (01-12)

---

## Implementation Sequence (Recommended)

### Phase 1: Foundation (Week 1)
1. âœ… Data Models (01)
2. âœ… LLM Client (02)
3. ðŸ”² Utils Package (13)

### Phase 2: Core Pipeline (Week 2-3)
4. âœ… Intent Extraction (03)
5. ðŸ”² Spec Generator (04)
6. ðŸ”² Code Generator (05)

### Phase 3: Validation (Week 3-4)
7. ðŸ”² Validator (06) - basic (skip Code BLEU for MVP)
8. ðŸ”² Repair Coordinator (11)

### Phase 4: Execution & Approval (Week 4-5)
9. ðŸ”² Executor (07)
10. ðŸ”² Presenter (08)
11. ðŸ”² Feedback Handler (09)
12. ðŸ”² Promoter (10)

### Phase 5: Integration (Week 5-6)
13. ðŸ”² Main Pipeline Orchestrator (14)
14. ðŸ”² End-to-end testing
15. ðŸ”² Documentation

### Phase 6: Enhancement (Post-MVP)
16. ðŸ”² Metrics Package (12) - full Code BLEU implementation
17. ðŸ”² Advanced features (multi-tool composition, etc.)

---

## Testing Strategy

### Unit Tests
- Each module: >90% coverage
- Mock external dependencies (LLM, file system)
- Test error paths

### Integration Tests
- Module pairs (e.g., Intent â†’ Spec â†’ Code)
- Real LLM calls (with caching)
- Sample dataset processing

### End-to-End Tests
- Complete pipeline: query â†’ tool â†’ approval â†’ promotion
- Multiple tool types (groupby, filter, join, etc.)
- Error recovery scenarios

---

## Next Steps

### Immediate Actions
1. âœ… Review completed PRs (01-03)
2. ðŸ”² Create PR for Spec Generator (04)
3. ðŸ”² Create PR for Code Generator (05)
4. ðŸ”² Create PR for Utils Package (13)
5. ðŸ”² Set up development environment
6. ðŸ”² Deploy Qwen2.5-Coder-32B with vLLM

### Week 1 Goals
- Complete foundation modules (Data Models, LLM Client, Utils)
- Unit tests passing for foundation
- vLLM server operational

---

## Module PR Template

Each module PR should contain:

1. **Module Purpose** - What and why
2. **Core Components** - Classes, functions
3. **Data Structures** - Input/output types
4. **Implementation** - Code with examples
5. **Testing Requirements** - Unit + integration tests
6. **Dependencies** - What it needs
7. **Configuration** - YAML/env vars
8. **Implementation Checklist** - Breakdown
9. **Estimated Effort** - Time estimate
10. **Examples** - Usage patterns

---

## Resources

- **Main PR**: `../ProjectRequirements.instructions.md`
- **Reference Files**: `../reference_files/sample_mcp_tools/`
- **Sample Outputs**: `../reference_files/sample_response_to_no_2/`
- **Config Template**: `../config.yaml` (to be created)

---

**Last Updated**: 2026-01-22  
**Next Review**: After completing Phase 1 modules  
**Maintainer**: MCP Tool Generator Team
